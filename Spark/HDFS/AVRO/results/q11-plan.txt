
== Physical Plan ==
*(15) Sort [part_ue#29401 DESC NULLS LAST], true, 0
+- Exchange rangepartitioning(part_ue#29401 DESC NULLS LAST, 200)
   +- BroadcastNestedLoopJoin BuildRight, Inner, (part_ue#29401 > (total_ue#29394 * 1.0E-4))
      :- *(7) Filter isnotnull(part_ue#29401)
      :  +- *(7) HashAggregate(keys=[ps_partkey#20], functions=[sum(ue#29390)])
      :     +- Exchange hashpartitioning(ps_partkey#20, 200)
      :        +- *(6) HashAggregate(keys=[ps_partkey#20], functions=[partial_sum(ue#29390)])
      :           +- *(6) Project [ps_partkey#20, (ps_supplycost#23 * cast(ps_availqty#22 as double)) AS ue#29390]
      :              +- *(6) SortMergeJoin [s_suppkey#32], [ps_suppkey#21], Inner
      :                 :- *(3) Sort [s_suppkey#32 ASC NULLS FIRST], false, 0
      :                 :  +- Exchange hashpartitioning(s_suppkey#32, 200)
      :                 :     +- *(2) Project [s_suppkey#32]
      :                 :        +- *(2) BroadcastHashJoin [n_nationkey#48], [s_nationkey#35], Inner, BuildLeft
      :                 :           :- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))
      :                 :           :  +- *(1) Project [n_nationkey#48]
      :                 :           :     +- *(1) Filter ((isnotnull(n_name#49) && StartsWith(n_name#49, ARGENTINA)) && isnotnull(n_nationkey#48))
      :                 :           :        +- *(1) FileScan avro [n_nationkey#48,n_name#49] Batched: false, Format: com.databricks.spark.avro.DefaultSource@555a0083, Location: InMemoryFileIndex[hdfs://namenode:8020/nation.avro], PartitionFilters: [], PushedFilters: [IsNotNull(n_name), StringStartsWith(n_name,ARGENTINA), IsNotNull(n_nationkey)], ReadSchema: struct<n_nationkey:int,n_name:string>
      :                 :           +- *(2) Project [s_suppkey#32, s_nationkey#35]
      :                 :              +- *(2) Filter (isnotnull(s_nationkey#35) && isnotnull(s_suppkey#32))
      :                 :                 +- *(2) FileScan avro [s_suppkey#32,s_nationkey#35] Batched: false, Format: com.databricks.spark.avro.DefaultSource@6e05add3, Location: InMemoryFileIndex[hdfs://namenode:8020/supplier.avro], PartitionFilters: [], PushedFilters: [IsNotNull(s_nationkey), IsNotNull(s_suppkey)], ReadSchema: struct<s_suppkey:int,s_nationkey:int>
      :                 +- *(5) Sort [ps_suppkey#21 ASC NULLS FIRST], false, 0
      :                    +- Exchange hashpartitioning(ps_suppkey#21, 200)
      :                       +- *(4) Project [ps_partkey#20, ps_suppkey#21, ps_availqty#22, ps_supplycost#23]
      :                          +- *(4) Filter isnotnull(ps_suppkey#21)
      :                             +- *(4) FileScan avro [ps_partkey#20,ps_suppkey#21,ps_availqty#22,ps_supplycost#23] Batched: false, Format: com.databricks.spark.avro.DefaultSource@a15fd8b, Location: InMemoryFileIndex[hdfs://namenode:8020/partsupp.avro], PartitionFilters: [], PushedFilters: [IsNotNull(ps_suppkey)], ReadSchema: struct<ps_partkey:int,ps_suppkey:int,ps_availqty:int,ps_supplycost:double>
      +- BroadcastExchange IdentityBroadcastMode
         +- *(14) Filter isnotnull(total_ue#29394)
            +- *(14) HashAggregate(keys=[], functions=[sum(ue#29390)])
               +- Exchange SinglePartition
                  +- *(13) HashAggregate(keys=[], functions=[partial_sum(ue#29390)])
                     +- *(13) Project [(ps_supplycost#23 * cast(ps_availqty#22 as double)) AS ue#29390]
                        +- *(13) SortMergeJoin [s_suppkey#32], [ps_suppkey#21], Inner
                           :- *(10) Sort [s_suppkey#32 ASC NULLS FIRST], false, 0
                           :  +- ReusedExchange [s_suppkey#32], Exchange hashpartitioning(s_suppkey#32, 200)
                           +- *(12) Sort [ps_suppkey#21 ASC NULLS FIRST], false, 0
                              +- Exchange hashpartitioning(ps_suppkey#21, 200)
                                 +- *(11) Project [ps_suppkey#21, ps_availqty#22, ps_supplycost#23]
                                    +- *(11) Filter isnotnull(ps_suppkey#21)
                                       +- *(11) FileScan avro [ps_suppkey#21,ps_availqty#22,ps_supplycost#23] Batched: false, Format: com.databricks.spark.avro.DefaultSource@a15fd8b, Location: InMemoryFileIndex[hdfs://namenode:8020/partsupp.avro], PartitionFilters: [], PushedFilters: [IsNotNull(ps_suppkey)], ReadSchema: struct<ps_suppkey:int,ps_availqty:int,ps_supplycost:double>
