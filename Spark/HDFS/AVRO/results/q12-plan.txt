== Physical Plan ==
*(8) Sort [l_shipmode#70 ASC NULLS FIRST], true, 0
+- Exchange rangepartitioning(l_shipmode#70 ASC NULLS FIRST, 200)
   +- *(7) HashAggregate(keys=[l_shipmode#70], functions=[sum(cast(<lambda>(o_orderpriority#95) as bigint)), sum(cast(<lambda>(o_orderpriority#95) as bigint))])
      +- Exchange hashpartitioning(l_shipmode#70, 200)
         +- *(6) HashAggregate(keys=[l_shipmode#70], functions=[partial_sum(cast(pythonUDF0#45070 as bigint)), partial_sum(cast(pythonUDF1#45071 as bigint))])
            +- BatchEvalPython [<lambda>(o_orderpriority#95), <lambda>(o_orderpriority#95)], [l_shipmode#70, o_orderpriority#95, pythonUDF0#45070, pythonUDF1#45071]
               +- *(5) Project [l_shipmode#70, o_orderpriority#95]
                  +- *(5) SortMergeJoin [l_orderkey#56], [o_orderkey#90], Inner
                     :- *(2) Sort [l_orderkey#56 ASC NULLS FIRST], false, 0
                     :  +- Exchange hashpartitioning(l_orderkey#56, 200)
                     :     +- *(1) Project [l_orderkey#56, l_shipmode#70]
                     :        +- *(1) Filter ((((((((isnotnull(l_commitdate#67) && isnotnull(l_receiptdate#68)) && isnotnull(l_shipdate#66)) && ((l_shipmode#70 = FOB) || (l_shipmode#70 = SHIP))) && (l_commitdate#67 < l_receiptdate#68)) && (l_shipdate#66 < l_commitdate#67)) && (l_receiptdate#68 >= 1994-01-01)) && (l_receiptdate#68 < 1995-01-01)) && isnotnull(l_orderkey#56))
                     :           +- *(1) FileScan avro [l_orderkey#56,l_shipdate#66,l_commitdate#67,l_receiptdate#68,l_shipmode#70] Batched: false, Format: com.databricks.spark.avro.DefaultSource@7bfb5a4, Location: InMemoryFileIndex[hdfs://namenode:8020/lineitem.avro], PartitionFilters: [], PushedFilters: [IsNotNull(l_commitdate), IsNotNull(l_receiptdate), IsNotNull(l_shipdate), Or(EqualTo(l_shipmode,..., ReadSchema: struct<l_orderkey:int,l_shipdate:string,l_commitdate:string,l_receiptdate:string,l_shipmode:string>
                     +- *(4) Sort [o_orderkey#90 ASC NULLS FIRST], false, 0
                        +- Exchange hashpartitioning(o_orderkey#90, 200)
                           +- *(3) Project [o_orderkey#90, o_orderpriority#95]
                              +- *(3) Filter isnotnull(o_orderkey#90)
                                 +- *(3) FileScan avro [o_orderkey#90,o_orderpriority#95] Batched: false, Format: com.databricks.spark.avro.DefaultSource@6fb4750c, Location: InMemoryFileIndex[hdfs://namenode:8020/orders.avro], PartitionFilters: [], PushedFilters: [IsNotNull(o_orderkey)], ReadSchema: struct<o_orderkey:int,o_orderpriority:string>