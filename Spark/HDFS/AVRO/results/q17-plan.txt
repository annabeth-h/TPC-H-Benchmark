
== Physical Plan ==
*(13) HashAggregate(keys=[], functions=[sum(l_extendedprice#61)])
+- Exchange SinglePartition
   +- *(12) HashAggregate(keys=[], functions=[partial_sum(l_extendedprice#61)])
      +- *(12) Project [l_extendedprice#61]
         +- *(12) SortMergeJoin [key#86864], [p_partkey#0], Inner, (l_quantity#60 < avg_quantity#86861)
            :- *(6) Sort [key#86864 ASC NULLS FIRST], false, 0
            :  +- Exchange hashpartitioning(key#86864, 200)
            :     +- *(5) Filter isnotnull(avg_quantity#86861)
            :        +- *(5) HashAggregate(keys=[p_partkey#0], functions=[avg(l_quantity#60)])
            :           +- *(5) HashAggregate(keys=[p_partkey#0], functions=[partial_avg(l_quantity#60)])
            :              +- *(5) Project [p_partkey#0, l_quantity#60]
            :                 +- SortMergeJoin [p_partkey#0], [l_partkey#57], LeftOuter
            :                    :- *(2) Sort [p_partkey#0 ASC NULLS FIRST], false, 0
            :                    :  +- Exchange hashpartitioning(p_partkey#0, 200)
            :                    :     +- *(1) Project [p_partkey#0]
            :                    :        +- *(1) Filter ((((isnotnull(p_brand#3) && isnotnull(p_container#6)) && (p_brand#3 = Brand#23)) && (p_container#6 = LG CAN)) && isnotnull(p_partkey#0))
            :                    :           +- *(1) FileScan avro [p_partkey#0,p_brand#3,p_container#6] Batched: false, Format: com.databricks.spark.avro.DefaultSource@754c2a03, Location: InMemoryFileIndex[hdfs://namenode:8020/part.avro], PartitionFilters: [], PushedFilters: [IsNotNull(p_brand), IsNotNull(p_container), EqualTo(p_brand,Brand#23), EqualTo(p_container,LG CA..., ReadSchema: struct<p_partkey:int,p_brand:string,p_container:string>
            :                    +- *(4) Sort [l_partkey#57 ASC NULLS FIRST], false, 0
            :                       +- Exchange hashpartitioning(l_partkey#57, 200)
            :                          +- *(3) FileScan avro [l_partkey#57,l_quantity#60] Batched: false, Format: com.databricks.spark.avro.DefaultSource@7bfb5a4, Location: InMemoryFileIndex[hdfs://namenode:8020/lineitem.avro], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<l_partkey:int,l_quantity:double>
            +- *(11) Project [p_partkey#0, l_quantity#60, l_extendedprice#61]
               +- *(11) SortMergeJoin [p_partkey#0], [l_partkey#57], Inner
                  :- *(8) Sort [p_partkey#0 ASC NULLS FIRST], false, 0
                  :  +- ReusedExchange [p_partkey#0], Exchange hashpartitioning(p_partkey#0, 200)
                  +- *(10) Sort [l_partkey#57 ASC NULLS FIRST], false, 0
                     +- Exchange hashpartitioning(l_partkey#57, 200)
                        +- *(9) Project [l_partkey#57, l_quantity#60, l_extendedprice#61]
                           +- *(9) Filter isnotnull(l_quantity#60)
                              +- *(9) FileScan avro [l_partkey#57,l_quantity#60,l_extendedprice#61] Batched: false, Format: com.databricks.spark.avro.DefaultSource@7bfb5a4, Location: InMemoryFileIndex[hdfs://namenode:8020/lineitem.avro], PartitionFilters: [], PushedFilters: [IsNotNull(l_quantity)], ReadSchema: struct<l_partkey:int,l_quantity:double,l_extendedprice:double>
